version: '2'
services:
  postgres:
    image: debezium/postgres:13
    ports:
      - 5432:5432
    healthcheck:
      test: "pg_isready -U ${DB_USERNAME} -d ${DB_DATABASE}"
      interval: 2s
      timeout: 20s
      retries: 10
    environment:
      - POSTGRES_USER=${DB_USERNAME}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_DATABASE}
      - PGPASSWORD=${DB_PASSWORD}
    volumes:
      - ./postgres-data:/var/lib/postgresql/data 
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    ports:
     - 9092:9092
    links:
     - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  schema-registry:
    image: confluentinc/cp-schema-registry:6.2.0
    hostname: schema-registry
    ports:
      - 8181:8181
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8181

  elastic:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.1
    ports:
     - "9200:9200"
    environment:
     - http.host=0.0.0.0
     - transport.host=127.0.0.1
     - xpack.security.enabled=false
     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  connect:
    image: debezium/connect-jdbc-es
    build:
      context: debezium-jdbc-es
    ports:
     - 8083:8083
     - 5005:5005
    links:
     - kafka
     - postgres
    environment:
     - BOOTSTRAP_SERVERS=kafka:9092
     - GROUP_ID=1
     - ADVERTISED_HOST_NAME=connect
     - CONFIG_STORAGE_TOPIC=my_connect_configs
     - OFFSET_STORAGE_TOPIC=my_connect_offsets
     - STATUS_STORAGE_TOPIC=my_source_connect_statuses
     - CONNECT_INTERNAL_KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
     - CONNECT_INTERNAL_VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter

  mongodb1:
    image: mongo:4
    restart: always
    container_name: mongodb1
    volumes:
      - mongodata1:/data/db
    expose:
      - "27017"
    entrypoint: [ "/usr/bin/mongod", "--replSet", "rsmongo", "--bind_ip_all", "--wiredTigerCacheSizeGB", "1"]
  mongodb2:
        image: mongo:4
        restart: always
        container_name: mongodb2
        volumes:
        - mongodata2:/data/db
        expose:
        - "27017"
        entrypoint: [ "/usr/bin/mongod", "--replSet", "rsmongo", "--bind_ip_all", "--wiredTigerCacheSizeGB", "1"]
  mongodb3:
        image: mongo:4
        restart: always
        container_name: mongodb3
        volumes:
        - mongodata3:/data/db
        expose:
        - "27017"
        entrypoint: [ "/usr/bin/mongod", "--replSet", "rsmongo", "--bind_ip_all", "--wiredTigerCacheSizeGB", "1" ]
  mongosetup:
        image: "mongo-setup"
        build: "./mongo-setup"
        container_name: "mongosetup"
        depends_on:
            - mongodb1
        volumes:
            - mongostatus:/data/
  mongoworker:
    image: vinomioworker
    container_name: "mongo-worker"

  vinomio:
    image: vinomioapi
    build:
      context: "../"
      dockerfile: Dockerfile
    container_name: "vinomioapi"
    environment:
      - NODE_ENV=development
      - JWTSECRET=${JWTSECRET}
      - DB_PORT=${DB_PORT}
      - DB_HOST=${DB_HOST}
      - PORT=${PORT}
      - DB_USERNAME=${DB_USERNAME}
      - DB_DATABASE=${DB_DATABASE}
      - DB_PASSWORD=${DB_PASSWORD}
    ports:
      - 3000:3000
    links:
      - postgres
    depends_on:
      - postgres

  vinomiostream:
    image: vinomiostream
    build:
      context: ./vinomio.event
      dockerfile: Dockerfile
    ports:
      - 7000:7000
    

volumes:
    mongodata1:
    mongodata2:
    mongodata3:
    mongostatus:
